# НТО 2025/2026 — ИИ — Этап 2А: Описание данных и формата решений

Этот документ является справочником по данным и формату файла решения для задачи «Этап 2А: Предсказание оценок».

---

## 1. Описание данных

**Основной формат исходных данных:** CSV с разделителем точка с запятой (`;`) и двойными кавычками (`"`) для экранирования текстовых полей.

### 1.0. Получение данных

Данные расположены по ссылке: [https://drive.google.com/drive/folders/1ioqrB9146B9DLcEVD7V3LIl46IYAyBfm](https://drive.google.com/drive/folders/1ioqrB9146B9DLcEVD7V3LIl46IYAyBfm)

#### Автоматическая загрузка

При запуске команды `make download-data` данные будут автоматически скачаны и подготовлены к использованию.

**Примечание:** Если команда `make download-data` завершается с ошибкой, это означает, что Google Drive временно заблокировал автоматическое скачивание через инструмент `gdown`. Это защита от массового скачивания, которая может срабатывать после нескольких попыток. В этом случае используйте ручную загрузку (см. ниже).

#### Ручная загрузка данных

Если автоматическая загрузка не работает, выполните следующие шаги:

1. **Скачайте файлы вручную:**
   - Откройте ссылку на Google Drive в браузере
   - Скачайте все CSV-файлы на ваш компьютер

2. **Поместите файлы в `data/raw/` и переименуйте их:**

3. **Проверьте, что все файлы на месте:**
   ```bash
   ls data/raw/
   ```

   Должны быть файлы: `train.csv`, `test.csv`, `users.csv`, `books.csv`, `book_genres.csv`, `genres.csv`, `book_descriptions.csv`

### 1.1. Состав предоставляемых файлов

| Файл | Описание |
|------|----------|
| `train.csv` | Обучающая выборка, соответствующая первому хронологическому срезу данных (chunk 1). Содержит полную историю взаимодействий пользователей за этот период, включая прочитанные книги (`has_read=1`) и книги в списке "на прочтение" (`has_read=0`). |
| `test.csv` | Тестовая выборка, содержащая взаимодействия из второго хронологического среза (chunk 2). Для каждого пользователя из тестовой выборки здесь представлена только одна пара (user_id, book_id), соответствующая его последнему прочитанному произведению. Важно: в test.csv включены только те пользователи, у которых есть достаточная история в train.csv. |
| `books.csv` | Метаданные книг (автор, год публикации и т.д.). |
| `users.csv` | Метаданные пользователей (пол, возраст). |
| `genres.csv` | Справочник жанров. |
| `book_genres.csv` | Таблица для связи книг и жанров (многие-ко-многим). |
| `book_descriptions.csv` | Текстовые описания книг. Используется для извлечения признаков через TF-IDF и BERT. |

### 1.2. Описание полей в метаданных

#### train.csv: Обучающая выборка

| Поле | Тип | Описание |
|------|-----|----------|
| `user_id` | int64 | Уникальный идентификатор пользователя. |
| `book_id` | int64 | Уникальный идентификатор книги. |
| `has_read` | int64 | Флаг взаимодействия: 1 - книга прочитана и оценена, 0 - книга добавлена в список "на прочтение" (не оценена). |
| `rating` | float64 | Оценка книги по шкале от 0 до 10. Для записей с `has_read=0` значение всегда равно 0 и является заглушкой. |
| `timestamp` | str | Временная метка взаимодействия в формате `YYYY-MM-DD HH:MM:SS`. |

**Важно:** В бейзлайне для обучения используются только записи с `has_read=1` (книги, которым была поставлена оценка). Записи с `has_read=0` исключаются из обучающей выборки.

#### Принципы формирования данных

1.  **Хронологическое разделение:** `train.csv` представляет собой первый по времени чанк данных (`chunk_1`), а данные для `test.csv` и `solution.csv` взяты из следующего чанка (`chunk_2`). Это гарантирует отсутствие утечек из будущего.

2.  **Фильтрация тестовой выборки:** В `test.csv` попадают не все взаимодействия из `chunk_2`, а только специально отобранные:
    - **Последнее взаимодействие:** Для каждого пользователя берется только одно, самое последнее по времени взаимодействие с флагом `has_read=1`.
    - **Фильтр "теплых" пользователей:** В `test.csv` включаются только те пользователи, у которых есть история в `train.csv`. Критерий: не менее 1 прочитанной книги (`has_read=1`) ИЛИ не менее 3 книг в списке "на прочтение" (`has_read=0`) в файле `train.csv`. Это гарантирует, что у участников будут исходные данные для всех пользователей из теста.

3.  **Очистка данных:** Из исходного набора данных были удалены аномальные записи, у которых `has_read=0`, но при этом `rating > 0`.

#### books.csv: Информация о книгах

| Поле | Тип | Описание |
|------|-----|----------|
| `book_id` | int64 | Уникальный идентификатор книги (первичный ключ). |
| `title` | str | Название книги. |
| `author_id` | int64 | Уникальный идентификатор автора. |
| `author_name` | str | Имя автора. |
| `publication_year` | int64 | Год публикации. |
| `language` | int64 | Числовой код языка книги. |
| `avg_rating` | float64 | Средняя оценка книги (рассчитана по всем взаимодействиям). |
| `publisher` | int64 | Числовой код издательства. |

#### users.csv: Информация о пользователях

| Поле | Тип | Описание |
|------|-----|----------|
| `user_id` | int64 | Уникальный идентификатор пользователя (первичный ключ). |
| `gender` | int64 | Пол пользователя (1 — мужской, 2 — женский). |
| `age` | int64 | Возраст пользователя. |

#### genres.csv: Справочник жанров

| Поле | Тип | Описание |
|------|-----|----------|
| `genre_id` | int64 | Уникальный идентификатор жанра (первичный ключ). |
| `genre_name` | str | Название жанра. |
| `books_count` | int64 | Общее количество книг в данном жанре. |

#### book_genres.csv: Связь книг и жанров

| Поле | Тип | Описание |
|------|-----|----------|
| `book_id` | int64 | Идентификатор книги (внешний ключ к books.csv). |
| `genre_id` | int64 | Идентификатор жанра (внешний ключ к genres.csv). |

#### book_descriptions.csv: Описания книг

| Поле | Тип | Описание |
|------|-----|----------|
| `book_id` | int64 | Идентификатор книги (внешний ключ к books.csv). |
| `description` | str | Текстовое описание книги. Может содержать пустые значения. |

**Примечание:** Описания используются для извлечения признаков двумя способами:
- **TF-IDF**: создание разреженных признаков на основе термов и биграмм из описаний
- **BERT embeddings**: получение плотных векторных представлений текста через предобученную модель `DeepPavlov/rubert-base-cased`

---

## 2. Формат файла решения (сабмита)

Файл с решением должен быть представлен в формате CSV с разделителем запятая (`,`). Файл может содержать заголовок, который будет проигнорирован при проверке.

**Структура колонок:** `user_id,book_id,rating_predict`

**Требования:**
- `user_id`, `book_id` — идентификаторы, соответствующие парам из файла `test.csv`. Порядок строк в файле решения не важен.
- `rating_predict` — предсказанное значение оценки. Вещественное число в диапазоне от 0 до 10. Округлять не требуется. Система автоматически ограничит значения диапазоном [0, 10].
- Файл должен содержать предсказания для всех пар из `test.csv`.
- Максимальный размер файла: 50 МБ.

**Пример содержимого submission.csv:**

```
user_id,book_id,rating_predict
150,25357,7.854
150,18,9.102
24995,136814,5.500
```
